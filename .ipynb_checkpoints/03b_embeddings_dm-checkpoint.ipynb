{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "data = make_swiss_roll(n_samples=n_samples, noise=0.0, random_state=None)\n",
    "data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[n_samples,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('pairwise_distance2'):\n",
    "    # pairwise distance matrix\n",
    "    r = tf.reduce_sum(tf.square(X), 1, keep_dims=True)\n",
    "    pwd2 = r - 2*tf.matmul(X, tf.transpose(X)) + tf.transpose(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,   53.58312988,   81.19294739, ...,  156.06951904,\n",
       "         141.34794617,  372.6083374 ],\n",
       "       [  53.58312988,    0.        ,  101.52854919, ...,  255.76797485,\n",
       "         107.93147278,  624.24072266],\n",
       "       [  81.19293213,  101.52856445,    0.        , ...,   88.21354675,\n",
       "          97.58770752,  343.46478271],\n",
       "       ..., \n",
       "       [ 156.06951904,  255.76797485,   88.21354675, ...,    0.        ,\n",
       "         361.53692627,  406.00140381],\n",
       "       [ 141.34794617,  107.93145752,   97.58770752, ...,  361.53692627,\n",
       "           0.        ,  397.99661255],\n",
       "       [ 372.6083374 ,  624.24072266,  343.46478271, ...,  406.00140381,\n",
       "         397.99664307,    0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(pwd2, {X: data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('kernel'):\n",
    "    W = tf.exp(-0.01*pwd2)\n",
    "    Ainv = tf.diag(1./tf.reduce_sum(W, 1))\n",
    "    I = tf.diag(tf.ones_like(W[:,0]))\n",
    "    laplacian = I - tf.matmul(Ainv, W)\n",
    "    # normalized laplacian is I - A^-1 W = A^-1 L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('embedding'):\n",
    "    e, v = tf.self_adjoint_eig(laplacian, name=\"eigendata\")\n",
    "    embedding = v[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# embedding = sess.run(embedding, {X:data})\n",
    "embedding_var = tf.Variable(embedding, name='word_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter('/tmp/embeddings03b/1')\n",
    "writer.add_graph(sess.graph)\n",
    "#\n",
    "config = projector.ProjectorConfig()\n",
    "embedding_config = config.embeddings.add()\n",
    "embedding_config.tensor_name = embedding.name\n",
    "##embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "##embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "# Specify the width and height of a single thumbnail.\n",
    "# embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "# You can add multiple embeddings. Here we add only one.\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "# Link this tensor to its metadata file (e.g. labels).\n",
    "# embedding.metadata_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "\n",
    "# Use the same LOG_DIR where you stored your checkpoint.\n",
    "summary_writer = tf.summary.FileWriter('/tmp/embeddings03b/2')\n",
    "\n",
    "# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "# read this file during startup.\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
